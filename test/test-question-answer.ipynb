{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6157d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shind\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Shind\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shind\\.cache\\huggingface\\hub\\models--potsawee--t5-large-generation-squad-QuestionAnswer. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "\n",
    "# Пример использования\n",
    "input_text = \"question: What is AI? context: Artificial intelligence is a branch of computer science.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Генерация ответа\n",
    "outputs = model.generate(input_ids)\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114832d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d968d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Answer: Artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\").to(device)\n",
    "\n",
    "# Пример использования\n",
    "input_text = \"question: What is AI? context: Artificial intelligence is a branch of computer science.\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)  # Перенос входных данных на GPU\n",
    "\n",
    "# Генерация ответа\n",
    "outputs = model.generate(input_ids)\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0454a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Sample 1\n",
      "Generated Answer: What is artificial intelligence? a branch of computer science\n",
      "Expected Answer : Artificial intelligence is a branch of computer science\n",
      "❌ Incorrect\n",
      "\n",
      "Sample 2\n",
      "Generated Answer: When was the Eiffel Tower built? 1889\n",
      "Expected Answer : Paris\n",
      "❌ Incorrect\n",
      "\n",
      "Sample 3\n",
      "Generated Answer: What is the standard atmospheric pressure? atmospheric pressure\n",
      "Expected Answer : 100 degrees Celsius\n",
      "❌ Incorrect\n",
      "\n",
      "Sample 4\n",
      "Generated Answer: What is the powerhouse of the cell? The mitochondria\n",
      "Expected Answer : mitochondria\n",
      "✅ Correct\n",
      "\n",
      "Sample 5\n",
      "Generated Answer: How many miles long is the Great Wall of China? over 13,000 miles\n",
      "Expected Answer : over 13,000 miles\n",
      "✅ Correct\n",
      "\n",
      "Sample 6\n",
      "Generated Answer: What century did Isaac Newton write his laws? 17th\n",
      "Expected Answer : Isaac Newton\n",
      "✅ Correct\n",
      "\n",
      "Sample 7\n",
      "Generated Answer: What percentage of the world's oxygen supply does the Amazon produce? 20%\n",
      "Expected Answer : Amazon rainforest\n",
      "❌ Incorrect\n",
      "\n",
      "Sample 8\n",
      "Generated Answer: What is Python known for? readability and wide range of libraries\n",
      "Expected Answer : Python\n",
      "✅ Correct\n",
      "\n",
      "Sample 9\n",
      "Generated Answer: What is the process by which green plants use sunlight to synthesize nutrients? Photosynthesis\n",
      "Expected Answer : Photosynthesis\n",
      "✅ Correct\n",
      "\n",
      "Sample 10\n",
      "Generated Answer: What is the speed of light in a vacuum? 299,792 kilometers per second\n",
      "Expected Answer : 299,792 kilometers per second\n",
      "✅ Correct\n",
      "\n",
      "Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\").to(device)\n",
    "\n",
    "# Тестовые данные: пары \"контекст\" и \"эталонный ответ\"\n",
    "samples = [\n",
    "    {\n",
    "        \"context\": \"Artificial intelligence is a branch of computer science that aims to create systems capable of intelligent behavior.\",\n",
    "        \"expected_answer\": \"Artificial intelligence is a branch of computer science\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The Eiffel Tower is located in Paris and was built in 1889 as the entrance arch for the World's Fair.\",\n",
    "        \"expected_answer\": \"Paris\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Water boils at 100 degrees Celsius under standard atmospheric pressure.\",\n",
    "        \"expected_answer\": \"100 degrees Celsius\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The mitochondria is often referred to as the powerhouse of the cell.\",\n",
    "        \"expected_answer\": \"mitochondria\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The Great Wall of China is over 13,000 miles long and was built to protect Chinese states from invasions.\",\n",
    "        \"expected_answer\": \"over 13,000 miles\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Isaac Newton formulated the laws of motion and universal gravitation in the 17th century.\",\n",
    "        \"expected_answer\": \"Isaac Newton\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The Amazon rainforest produces more than 20% of the world's oxygen supply.\",\n",
    "        \"expected_answer\": \"Amazon rainforest\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Python is a high-level, interpreted programming language known for its readability and wide range of libraries.\",\n",
    "        \"expected_answer\": \"Python\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"Photosynthesis is the process by which green plants use sunlight to synthesize nutrients from carbon dioxide and water.\",\n",
    "        \"expected_answer\": \"Photosynthesis\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": \"The speed of light in a vacuum is approximately 299,792 kilometers per second.\",\n",
    "        \"expected_answer\": \"299,792 kilometers per second\"\n",
    "    }\n",
    "]\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    input_text = f\"context: {sample['context']}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(input_ids, max_length=100)\n",
    "    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Разделим на вопрос и ответ\n",
    "    if \"<sep>\" in output:\n",
    "        try:\n",
    "            question, predicted_answer = output.split(\"<sep>\")\n",
    "        except:\n",
    "            predicted_answer = output.strip()\n",
    "    else:\n",
    "        predicted_answer = output.strip()\n",
    "\n",
    "    expected = sample['expected_answer'].lower()\n",
    "    predicted = predicted_answer.lower()\n",
    "\n",
    "    is_correct = expected in predicted or predicted in expected\n",
    "    correct += int(is_correct)\n",
    "\n",
    "    print(f\"\\nSample {i + 1}\")\n",
    "    print(\"Generated Answer:\", predicted_answer)\n",
    "    print(\"Expected Answer :\", sample['expected_answer'])\n",
    "    print(\"✅ Correct\" if is_correct else \"❌ Incorrect\")\n",
    "\n",
    "accuracy = correct / len(samples) * 100\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "lecture_notes = \"\"\"\n",
    "Artificial Intelligence (AI) is a branch of computer science focused on creating intelligent machines that can perform tasks typically requiring human intelligence.\n",
    "These tasks include learning, reasoning, problem-solving, perception, and language understanding.\n",
    "One of the earliest successful AI applications is expert systems, which mimic the decision-making abilities of human experts.\n",
    "Modern AI heavily relies on machine learning, especially deep learning, where artificial neural networks are used to model complex patterns in data.\n",
    "AI has a wide range of applications, including self-driving cars, virtual assistants, medical diagnostics, and financial forecasting.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2320a7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1: What is the branch of computer science focused on creating intelligent machines?\n",
      "  A) mathematics\n",
      "  B) physics\n",
      "  C) chemistry\n",
      "  D) Artificial Intelligence\n",
      "Correct Answer: D\n",
      "\n",
      "Question 2: What are some of the tasks that students are asked to do in a context?\n",
      "  A) mathematics\n",
      "  B) physics\n",
      "  C) robotics\n",
      "  D) learning, reasoning, problem-solving, perception, and language understanding\n",
      "Correct Answer: D\n",
      "\n",
      "Question 3: What is one of the earliest successful AI applications?\n",
      "  A) human resources\n",
      "  B) quantum computing\n",
      "  C) chemistry\n",
      "  D) expert systems\n",
      "Correct Answer: D\n",
      "\n",
      "Question 4: What is deep learning used for?\n",
      "  A) mathematics\n",
      "  B) to model complex patterns in data\n",
      "  C) chemistry\n",
      "  D) statistics\n",
      "Correct Answer: B\n",
      "\n",
      "Question 5: What is one of the applications of AI?\n",
      "  A) quantum computing\n",
      "  B) self-driving cars\n",
      "  C) human resources\n",
      "  D) chemistry\n",
      "Correct Answer: B\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import random\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"potsawee/t5-large-generation-squad-QuestionAnswer\").to(device)\n",
    "\n",
    "lecture_notes = \"\"\"\n",
    "Artificial Intelligence (AI) is a branch of computer science focused on creating intelligent machines that can perform tasks typically requiring human intelligence.\n",
    "These tasks include learning, reasoning, problem-solving, perception, and language understanding.\n",
    "One of the earliest successful AI applications is expert systems, which mimic the decision-making abilities of human experts.\n",
    "Modern AI heavily relies on machine learning, especially deep learning, where artificial neural networks are used to model complex patterns in data.\n",
    "AI has a wide range of applications, including self-driving cars, virtual assistants, medical diagnostics, and financial forecasting.\n",
    "\"\"\"\n",
    "\n",
    "# Разделим на 3-4 предложения (логически)\n",
    "contexts = lecture_notes.strip().split(\"\\n\")\n",
    "\n",
    "questions = []\n",
    "\n",
    "for i, context in enumerate(contexts):\n",
    "    input_text = f\"context: {context}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(input_ids, max_length=100)\n",
    "    qa = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"?\" in qa:\n",
    "        question, answer = qa.split(\"?\")\n",
    "        question = question.strip() + \"?\"\n",
    "        answer = answer.strip()\n",
    "    else:\n",
    "        continue  # если нет корректного вопроса\n",
    "\n",
    "    # Генерация distractors вручную (можно заменить на генерацию через другую модель)\n",
    "    distractors = [\n",
    "        \"robotics\", \"mathematics\", \"physics\", \"statistics\",\n",
    "        \"chemistry\", \"economics\", \"quantum computing\", \"human resources\"\n",
    "    ]\n",
    "    options = [answer] + random.sample(distractors, 3)\n",
    "    random.shuffle(options)\n",
    "    correct_option = [\"A\", \"B\", \"C\", \"D\"][options.index(answer)]\n",
    "\n",
    "    questions.append({\n",
    "        \"question\": question,\n",
    "        \"options\": {\n",
    "            \"A\": options[0],\n",
    "            \"B\": options[1],\n",
    "            \"C\": options[2],\n",
    "            \"D\": options[3]\n",
    "        },\n",
    "        \"answer\": correct_option\n",
    "    })\n",
    "\n",
    "# Выводим\n",
    "for idx, q in enumerate(questions):\n",
    "    print(f\"\\nQuestion {idx+1}: {q['question']}\")\n",
    "    for opt, val in q[\"options\"].items():\n",
    "        print(f\"  {opt}) {val}\")\n",
    "    print(f\"Correct Answer: {q['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2bb4ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shind\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Shind\\.cache\\huggingface\\hub\\models--potsawee--t5-large-generation-race-Distractor. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated distractors:\n",
      "1: Paris\n",
      "2: Paris.\n",
      "3: New York\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "model_name = \"potsawee/t5-large-generation-race-Distractor\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Входной текст для генерации отвлекающих вариантов\n",
    "input_text = \"question: What is the capital of France? context: France is a country in Europe. Its capital is Paris.\"\n",
    "\n",
    "# Токенизация входного текста\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Генерация отвлекающих вариантов\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=50,\n",
    "    num_return_sequences=3,  # Количество отвлекающих вариантов\n",
    "    num_beams=5,            # Использование beam search\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# Декодирование и вывод результатов\n",
    "distractors = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "print(\"Generated distractors:\")\n",
    "for i, distractor in enumerate(distractors, 1):\n",
    "    print(f\"{i}: {distractor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d91a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
